{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis with Pandas\n",
    "Now that we have the fundamental knowledge about Python and in particular Pandas we can start to do some exploratory data analysis (EDA). EDA is the first step in the data science process and it is very important to understand the data that we are working with. EDA is used by data scientists to understand the data, to identify patterns, to spot anomalies, to test hypothesis and to check assumptions with the help of summary statistics and graphical representations.\n",
    "\n",
    "\n",
    "In this notebook, we will see how to load data, and do an initial exploration of the data over the titanic dataset.  In 1912, during its maiden voyage, the widely considered \"unsinkable\" RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren’t enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n",
    "With this analysis, we will be able to answer some questions like:\n",
    "- What is the distribution of the passengers by age?\n",
    "- Who were the passengers in the Titanic?\n",
    "- What deck were the passengers on and how does that relate to their class?\n",
    "- Where did the passengers come from?\n",
    "- Who was alone and who was with family?\n",
    "- What factors helped someone survive the sinking?\n",
    "- Did the deck have an effect on the passengers survival rate?\n",
    "- Did having a family member increase the odds of surviving the crash?\n",
    "- etc.\n",
    "\n",
    "references:\n",
    "- https://www.kaggle.com/learn/pandas\n",
    "- Navlani, A.,  Fandango, A.,  Idris, I. (2021). Python Data Analysis: Perform data collection, data processing, wrangling, visualization, and model building using Python. Packt. 3rd Edition\n",
    "- Brandt. S. (2014). Data Analysis: Statistical and Computational Methods for Scientists and Engineers. Springer. 4th Edition\n",
    "\n",
    "\n",
    "- https://eugenelohh.medium.com/data-analysis-on-the-titanic-dataset-using-python-7593633135f2\n",
    "- https://medium.datadriveninvestor.com/hypothesis-testing-intuitively-explained-using-the-titanic-dataset-in-python-5afa1e580ba6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "Let's start with the Titanic data set. This is a very famous data set that is used to demonstrate data analysis and machine learning. It is a very small data set, but it is a good place to start. The data set is available, e.g., on Kaggle (https://www.kaggle.com/datasets/vinicius150987/titanic3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-09T22:53:33.683311Z",
     "end_time": "2023-04-09T22:53:33.728402Z"
    }
   },
   "outputs": [],
   "source": [
    "# load necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas_bokeh\n",
    "pandas_bokeh.output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-09T22:53:33.728366Z",
     "end_time": "2023-04-09T22:53:33.802621Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('./data/titanic/Titanic.xls')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data set has 1309 rows and 14 columns. Let's see what the columns and their data types are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-09T22:53:33.806164Z",
     "end_time": "2023-04-09T22:53:33.813213Z"
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns are:\n",
    "- pclass: Passenger class (1 = 1st; 2 = 2nd; 3 = 3rd)\n",
    "- survived: Survival (0 = No; 1 = Yes)\n",
    "- name: Name\n",
    "- sex: Sex  (male = Male; female = Female)\n",
    "- age: Age  (in years)\n",
    "- sibsp: Number of siblings/spouses aboard. The dataset defines family relations in this way:\n",
    "    - Sibling = brother, sister, stepbrother, stepsister\n",
    "    - Spouse = husband, wife (mistresses and fiancés were ignored)\n",
    "- parch: Number of Parents/Children Aboard. The dataset defines family relations in this way:\n",
    "    - Parent = mother, father\n",
    "    - Child = daughter, son, stepdaughter, stepson\n",
    "    Some children travelled only with a nanny, therefore parch=0 for them.\n",
    "- ticket: Ticket Number\n",
    "- fare: Passenger Fare\n",
    "- cabin: Cabin Number\n",
    "- embarked: Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)\n",
    "- boat: Lifeboat Number\n",
    "- body: Body Number (if did not survive and body was recovered)\n",
    "- home.dest: Home/Destination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are missing values in the age and body columns. This is also visible running the describe method. The include='all' argument allows to see the summary of the non-numerical columns (to include top - most frequent value; freq - frequency of the most frequent value; unique - number of unique values; and the other seams to be self-explanatory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-09T22:53:33.813435Z",
     "end_time": "2023-04-09T22:53:33.881828Z"
    }
   },
   "outputs": [],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us add a new column to the data frame with the family size. This is the sum of the number of siblings/spouses and the number of parents/children, plus 1 for the passenger itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-09T22:53:33.844467Z",
     "end_time": "2023-04-09T22:53:33.893323Z"
    }
   },
   "outputs": [],
   "source": [
    "df['family_size'] = df['sibsp'] + df['parch'] + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the data (a first look)\n",
    "We can plot the **histogram** of the numerical columns to see how the data is distributed. (https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.hist.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-09T22:53:33.851664Z",
     "end_time": "2023-04-09T22:53:35.352475Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot histograms of the numerical columns\n",
    "_ = df.hist(figsize=(15, 10), bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"> - what conclusion can you draw from the histogram of the age column? </span>\n",
    "<span style=\"color:red\"> - what conclusion can you draw from the histogram of the fare column? </span>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also useful to plot the bar charts of the categorical columns. We can do this using the value_counts() method from Pandas to get the count of unique values in each column and then plot the bar charts. (https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.bar.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-09T22:53:35.355754Z",
     "end_time": "2023-04-09T22:53:35.980221Z"
    }
   },
   "outputs": [],
   "source": [
    "# get the categorical columns\n",
    "cat_cols = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "# plot the bar charts of the categorical columns\n",
    "for col in cat_cols:\n",
    "    df_temp = df[col].value_counts()\n",
    "    # plot only the dataframes with less than 30 unique values - this will remove, e.g., the name, ticket and cabin column\n",
    "    if df_temp.size < 30:\n",
    "        df_temp.plot(kind='bar', title=col, figsize=(30, 5))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"> - what conclusion can you draw from the bar charts? </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivot tables and group by methods\n",
    "\n",
    "Pivot tables and group by methods are a very useful tool to summarize data.\n",
    "### Pivot table\n",
    "The pivot table method allows to summarize data by grouping the data by one or more columns and applying an aggregation function to the other columns. The pivot_table method is very similar to the groupby method. Its arguments include:\n",
    "- index: column(s) to group by on the rows\n",
    "- columns: column(s) to group by on the columns\n",
    "- values: column(s) to apply the aggregation function on\n",
    "- aggfunc: aggregation function to apply. Default is mean if values is a numerical column and count if values is a categorical column. Other possible values are sum, min, max, std, var, median, first, last, nunique, and size.\n",
    "- fill_value: value to replace missing values, default is 0. If you want to keep the missing values, you can use np.nan.\n",
    "- margins: add row/column subtotals and grand total (default is False)\n",
    "- margins_name: name of the row/column subtotals and grand total (default is 'All')\n",
    "- dropna: do not include columns whose entries are all NaN (default is True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, if you want to summarize the number of survived passengers into a pivot table with sex and pclass as the index and columns, respectvely, you can do the call below. In this case, the aggfunc is sum as we want to count the number of survived passengers and survived is a boolean column, where 1 survived and 0 did not survive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-09T22:53:35.982175Z",
     "end_time": "2023-04-09T22:53:36.035620Z"
    }
   },
   "outputs": [],
   "source": [
    "pt = df.pivot_table(index='sex', values='survived', columns='pclass', aggfunc='sum', margins=True, margins_name='Total')\n",
    "pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"> What was the total number of passengers that survived? </span>\n",
    "\n",
    "<span style=\"color:red\"> How many passerenger from class 1 survived? </span>\n",
    "\n",
    "<span style=\"color:red\"> How many female passengers survived? </span>\n",
    "\n",
    "<span style=\"color:red\"> Who did survive more: females or males? </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To present the pivot table with percentages we can divide it by the total number of passengers that survived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-09T22:53:36.010783Z",
     "end_time": "2023-04-09T22:53:36.035993Z"
    }
   },
   "outputs": [],
   "source": [
    "number_of_survived = sum(df['survived'])\n",
    "pt / number_of_survived"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"> In a similar manner, how can you summarize the passengers that did not survive? </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-09T22:53:36.014039Z",
     "end_time": "2023-04-09T22:53:36.036412Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pivot table can be plotted using a bar plot showing the number of survived passerger by gender a passenger class. The drop method is used to drop the Total row and column from the pivot table.\n",
    "\n",
    "Besides, we are also using __pandas Bokeh__ to plot the pivot table. This is a wrapper around the bokeh library that allows to plot pandas dataframes and series. The plot method has approximatly the same arguments as the pivot_table method. The plot method returns a bokeh figure object that can be used to customize the plot. For example, we can change the title of the plot and the labels of the axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-09T22:53:36.050024Z",
     "end_time": "2023-04-09T22:53:36.148303Z"
    }
   },
   "outputs": [],
   "source": [
    "_ = pt.drop('Total', axis=1).drop('Total', axis=0).plot_bokeh(kind='bar', title='Survived passengers per gender and class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stacked bar plot is useful to more easily see the proportion of survived passengers within each gender and passenger class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-09T22:53:36.113348Z",
     "end_time": "2023-04-09T22:53:36.213643Z"
    }
   },
   "outputs": [],
   "source": [
    "# pt.drop('Total', axis=1).drop('Total', axis=0).plot(kind='bar', stacked=True)\n",
    "_ = pt.drop('Total', axis=1).drop('Total', axis=0).plot_bokeh(kind='bar', stacked=True, title='Survived passengers per gender and class')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transpose of the pivot table allows for a different visualization (note the \".T\"). Now, each bar is associated to the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-09T22:53:36.170786Z",
     "end_time": "2023-04-09T22:53:36.253391Z"
    }
   },
   "outputs": [],
   "source": [
    "pt.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the corresponding bar plot is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-09T22:53:36.218761Z",
     "end_time": "2023-04-09T22:53:36.255975Z"
    }
   },
   "outputs": [],
   "source": [
    "# pt.drop('Total', axis=1).drop('Total', axis=0).T.plot(kind='bar', stacked=True)\n",
    "_ = pt.drop('Total', axis=1).drop('Total', axis=0).T.plot_bokeh(kind='bar', stacked=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another interesting graph are pie plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-09T22:53:36.260072Z",
     "end_time": "2023-04-09T22:53:36.402654Z"
    }
   },
   "outputs": [],
   "source": [
    "#pt.drop('Total', axis=1).drop('Total', axis=0).plot(kind='pie', subplots=True, figsize=(15, 10), autopct='%1.1f%%')\n",
    "_ = pt.drop('Total', axis=1).drop('Total', axis=0).plot_bokeh(kind='pie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-09T22:53:36.428555Z",
     "end_time": "2023-04-09T22:53:36.502389Z"
    }
   },
   "outputs": [],
   "source": [
    "_ = pt.T.drop('Total', axis=1).drop('Total', axis=0).plot_bokeh(kind='pie')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"> In which class did a greater proportion of males survive compared to females? </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make a pivot table with multiple values. For example, we can make a pivot table indexing the values of survived and sex, and columns by pclass and values by ticket (we will be just couting the ticket and, remember, the tickets' column has no missing values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-09T22:53:36.485728Z",
     "end_time": "2023-04-09T22:53:36.524593Z"
    }
   },
   "outputs": [],
   "source": [
    "pt_multi = df.pivot_table(index=['survived','sex'], values='ticket', columns='pclass', aggfunc='count', margins=True, margins_name='Total')\n",
    "pt_multi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"> how many passenger were in class 1?</span>\n",
    "<span style=\"color:red\"> how many females passengers did not survive? And how many males?</span>\n",
    "<span style=\"color:red\"> how many females passengers from class 1 did not survive? And how many males?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the pie plot is given by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-09T22:53:36.509349Z",
     "end_time": "2023-04-09T22:53:36.657883Z"
    }
   },
   "outputs": [],
   "source": [
    "_ = pt_multi.drop('Total', axis=1).drop('Total', axis=0).plot_bokeh(kind='pie', stacked=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"> What is represented by the largest orange \"arch\"?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group by method\n",
    "\n",
    "The group by method is another way to summarize data. It is more flexible than the pivot table method, but it is more difficult to use. The groupby method is used to split the data into groups based on one or more columns and then apply an aggregation function to each group. The groupby method returns a SeriesGroupBy object. This object can be used to apply an aggregation function to each group. The aggregation function can be applied to all the columns or to a specific column. Some arguments arguments are:\n",
    "- by: column(s) to group by\n",
    "- axis: axis to group by (default is 0)\n",
    "- as_index: group by as index (default is True)\n",
    "- sort: sort group keys (default is True)\n",
    "- observed: only show observed values for categorical groupers (default is False)\n",
    "\n",
    "For example, grouping by passengers class and gender and summing the survived column gives a similar result as the pivot table above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-09T22:53:36.655008Z",
     "end_time": "2023-04-09T22:53:36.666512Z"
    }
   },
   "outputs": [],
   "source": [
    "grp = df.groupby(['sex', 'pclass'])['survived'].sum()\n",
    "grp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the same result as the pivot table, we can unstack the SeriesGroupBy object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-09T22:53:36.660478Z",
     "end_time": "2023-04-09T22:53:36.682285Z"
    }
   },
   "outputs": [],
   "source": [
    "grp = grp.unstack()\n",
    "grp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second example shown above can also be done using groupby and unstack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-09T22:53:36.667334Z",
     "end_time": "2023-04-09T22:53:36.732557Z"
    }
   },
   "outputs": [],
   "source": [
    "df.groupby(['survived', 'sex', 'pclass'])['ticket'].count().unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "<span style=\"color:red\"> Find the minimum/maximum fare paid by each passenger class and gender.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"> Find the minimum/maximum fare paid by each adult (age>18) passenger by class and gender.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"> Add a row to the index of the previous pivot table dividing the results in adult and juvenile.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-09T22:53:36.676846Z",
     "end_time": "2023-04-09T22:53:36.735703Z"
    }
   },
   "outputs": [],
   "source": [
    "df.pivot_table(index=['pclass', 'sex'], values='fare', aggfunc=['min', 'max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-09T22:53:36.696181Z",
     "end_time": "2023-04-09T22:53:36.768011Z"
    }
   },
   "outputs": [],
   "source": [
    "df[df['age'] >= 18].pivot_table(index=['pclass', 'sex'], values='fare', aggfunc=['min', 'max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-09T22:53:36.715139Z",
     "end_time": "2023-04-09T22:53:36.768503Z"
    }
   },
   "outputs": [],
   "source": [
    "df_with_age_group = df.copy()\n",
    "df_with_age_group['age_group'] = df['age'].apply(lambda x: 'adult' if x >= 18 else 'juvenile')\n",
    "df_with_age_group.pivot_table(index=['age_group','pclass', 'sex'], values='fare', aggfunc=['min', 'max'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical analysis\n",
    "\n",
    "Exploratory data analysis (EDA) is not only about visualizing the data, but also about understanding the data. This is done by performing statistical analysis on it.\n",
    "\n",
    "### Types of variables\n",
    "\n",
    "Data types are fundamental concepts in statistical  analysis, being divided into the following main categories:\n",
    "- **Nominal attributes** refer to variables that are categorized by names or labels. These variables have categorical, qualitative, and unordered values, such as brand names, product names, zip codes, gender, or marital status. The value of a nominal attribute can be represented by the symbol or name of an item. It is not meaningful to calculate the mean or median values for nominal attributes, but data analysts can calculate the mode, which is the value that appears most frequently.\n",
    "\n",
    "- **Ordinal attributes** are variables that have names or labels with a meaningful order or ranking, but their exact magnitude is unknown. These attributes measure subjective qualities, which make them ideal for surveys that collect information on customer satisfaction, product ratings, and movie reviews. For example, customer satisfaction ratings may range from very dissatisfied to very satisfied, or the size of a drink may be classified as small, medium, or large. The median and mode are the only measures of central tendency that should  be used for ordinal attributes, as the mean cannot be calculated due to their qualitative nature.\n",
    "\n",
    "- **Numeric attributes** are variables that are quantitatively represented as either integer or real values. For example, the number of children in a family is a numeric attribute. The mean, median, and mode are all appropriate measures of central tendency for numeric attributes.\n",
    "\n",
    "#### Discrete and continuous variables\n",
    "\n",
    "Variables can be divided into two main categories:\n",
    "- **discrete variables** are variables that can take on only a finite number of values. For example, the number of children in a family is a discrete variable, as it can only take on the values 0, 1, 2, 3, etc.\n",
    "- **continuous variables** are variables that can take on an infinite number of values. For example, the height of a person is a continuous variable, as it can take on any value between 0 and ? meters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measures of central tendency\n",
    "#### Mean\n",
    "The mean is the most common measure of central tendency. It is the sum of all values divided by the number of values. The mean is a good measure of central tendency for continuous variables. However, it is not a good measure of central tendency for discrete variables, as it is sensitive to outliers. The mean is calculated using the following formula:\n",
    "$$\\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n}x_i$$\n",
    "where $x_i$ is the $i$-th value of the variable and $n$ is the number of values.\n",
    "\n",
    "For examples the mean of the age of the passengers is given by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-09T22:53:36.731920Z",
     "end_time": "2023-04-09T22:53:36.768715Z"
    }
   },
   "outputs": [],
   "source": [
    "df['age'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Median\n",
    "The median is the middle value of a sorted list of values. If the number of values is even, the median is the average of the two middle values. The median is a good measure of central tendency for both discrete and continuous variables. The median is calculated using the following formula:\n",
    "$$\\text{median} = \\begin{cases} \\frac{x_{\\frac{n}{2}} + x_{\\frac{n+1}{2}}}{2} & \\text{if } n \\text{ is even} \\\\ x_{\\frac{n+1}{2}} & \\text{if } n \\text{ is odd} \\end{cases}$$\n",
    "where $x_i$ is the $i$-th value of the variable and $n$ is the number of values.\n",
    "\n",
    "For example, the median of the age of the passengers is given by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-09T22:53:36.736986Z",
     "end_time": "2023-04-09T22:53:36.794715Z"
    }
   },
   "outputs": [],
   "source": [
    "df['age'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Along with the median it is usual to define the percentile of a variable. The $p$-th percentile of a variable is the value $x_p$ such that $p$% of the values are less than or equal to $x_p$. For example, the 25th percentile of the age of the passengers is given by the value such that 25% of the values are less than or equal to it.\n",
    "\n",
    "To get the 25th percentile of the age of the passengers we can use `quantile` method with the parameter q=0.25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-09T22:53:36.739597Z",
     "end_time": "2023-04-09T22:53:36.817161Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"25% of the passengers are younger than\", df['age'].quantile(q=0.25), \"years old.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mode\n",
    "The mode is the value that appears most frequently in a list of values. The mode is a good measure of central tendency for nominal variables.\n",
    "\n",
    "For example, the mode of the embarked column is given by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-09T22:53:36.747371Z",
     "end_time": "2023-04-09T22:53:36.883721Z"
    }
   },
   "outputs": [],
   "source": [
    "df['embarked'].mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `value_counts` method can be used to count the number of times each value appears in a column and check if the mode is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-09T22:53:36.752322Z",
     "end_time": "2023-04-09T22:53:36.883930Z"
    }
   },
   "outputs": [],
   "source": [
    "df['embarked'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measures of dispersion\n",
    "\n",
    "#### Range\n",
    "The range is the difference between the maximum and minimum values of a variable. The range is a good measure of dispersion for discrete variables. However, it is not a good measure of dispersion for continuous variables, as it is sensitive to outliers. The range is calculated using the following formula:\n",
    "$$\\text{range}(x) = x_{\\text{max}} - x_{\\text{min}}$$\n",
    "where $x_{\\text{max}}$ is the maximum value of the variable and $x_{\\text{min}}$ is the minimum value of the variable.\n",
    "\n",
    "For example, the range of the age of the passengers is given by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-09T22:53:36.756495Z",
     "end_time": "2023-04-09T22:53:36.884127Z"
    }
   },
   "outputs": [],
   "source": [
    "df['age'].max() - df['age'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variance and standard deviation\n",
    "The variance is the average of the squared differences from the mean. The variance is a good measure of dispersion for continuous variables. The variance is calculated using the following formula:\n",
    "$$\\text{var}(x) = \\frac{1}{n}\\sum_{i=1}^{n}(x_i - \\bar{x})^2$$\n",
    "where $x_i$ is the $i$-th value of the variable, $\\bar{x}$ is the mean of the variable, and $n$ is the number of values.\n",
    "\n",
    "For example, the variance of the age of the passengers is given by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-09T22:53:36.760771Z",
     "end_time": "2023-04-09T22:53:36.884746Z"
    }
   },
   "outputs": [],
   "source": [
    "df['age'].var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, the standard deviation is the square root of the variance. The standard deviation is also a good measure of dispersion for continuous variables. The standard deviation is calculated using the following formula:\n",
    "$$\\text{std}(x) = \\sqrt{\\text{var}(x)}.$$\n",
    "\n",
    "The standard deviation is on the most common measure of dispersion being measured in the same units as the variable.\n",
    "\n",
    "For example, the standard deviation of the age of the passengers is given by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-09T22:53:36.767176Z",
     "end_time": "2023-04-09T22:53:36.884910Z"
    }
   },
   "outputs": [],
   "source": [
    "df['age'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interquartile range (IQR)\n",
    "The interquartile range is the difference between the 75th and 25th percentiles of a variable. The interquartile range is a good measure of dispersion for continuous variables. The interquartile range is calculated using the following formula:\n",
    "$$\\text{IQR}(x) = x_{75} - x_{25}$$\n",
    "where $x_{75}$ is the 75th percentile of the variable and $x_{25}$ is the 25th percentile of the variable.\n",
    "\n",
    "For example, the interquartile range of the age of the passengers is given by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-09T22:53:36.777793Z",
     "end_time": "2023-04-09T22:53:36.885037Z"
    }
   },
   "outputs": [],
   "source": [
    "df['age'].quantile(0.75) - df['age'].quantile(0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measures of skewness and kurtosis\n",
    "\n",
    "#### Skewness\n",
    "\n",
    "Skewness measures the symmetry of a distribution. A distribution is symmetric if it looks the same to the left and right of the center point. A distribution is skewed if it is longer in one tail than the other. The skewness of a distribution is:\n",
    "  - **positive if the tail on the right side of the distribution is longer** (that is, outliers are skewed to the right and data stacked up on the left) and\n",
    "  - **negative if the tail on the left side of the distribution is longer**.\n",
    "  - The skewness of a distribution is **zero** if the tails on both sides of the distribution are the same length.\n",
    "\n",
    "Further positive skewness occurs when the mean is greater than the median and the mode. Negative skewness occurs when the mean is less than the median and mode.\n",
    "\n",
    "Let us calculate the skewness of the numeric attributes of the titanic dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-09T22:53:36.784572Z",
     "end_time": "2023-04-09T22:53:36.885188Z"
    }
   },
   "outputs": [],
   "source": [
    "numeric_attributes = df.select_dtypes(include=['int64', 'float64'])\n",
    "\n",
    "df[numeric_attributes.columns].skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without looking at the histogram plot:\n",
    "<span style=\"color:red\"> what conclusions can you take about the distibution of the pclass?</span>\n",
    "<span style=\"color:red\"> what conclusions can you take about the distibution of the fare?</span>\n",
    "<span style=\"color:red\"> what conclusions can you take about the distibution of the age?</span>\n",
    "\n",
    "<span  style=\"color:red\"> Replot the histogram of the pclass, fare and age attributes and comment on the skewness of the distributions.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-09T22:53:36.791040Z",
     "end_time": "2023-04-09T22:53:36.885346Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kurtosis\n",
    "kurtoisis measures the tail heaviness of a distribution, i.e., whether the tails are heavy or light relative to a normal distribution. The kurtosis of a distribution is positive if the tails are heavier than a normal distribution and negative if the tails are lighter than a normal distribution.\n",
    "\n",
    "Let us calculate the kurtosis of the numeric attributes of the titanic dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-09T22:53:36.797672Z",
     "end_time": "2023-04-09T22:53:36.885806Z"
    }
   },
   "outputs": [],
   "source": [
    "df[numeric_attributes.columns].kurt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-09T22:53:36.803803Z",
     "end_time": "2023-04-09T22:53:36.886079Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_histogram_and_normal_dist(df, column, bins=10):\n",
    "\n",
    "    mean_age = df[column].mean()\n",
    "    std_age = df[column].std()\n",
    "\n",
    "    normal_dist = np.random.normal(mean_age, std_age, 10000)\n",
    "\n",
    "    df[column].plot(kind='hist', figsize=(15,5), bins=bins, density=True, alpha=0.5, color='red', title=f'Histogram of a normal distribution and \"{column}\" which has has a swewness of {df[column].skew():.2f} and a kurtosis of {df[column].kurt():.2f}')\n",
    "    plt.hist(normal_dist, bins=2*bins, density=True, alpha=0.5, color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-09T22:53:36.807245Z",
     "end_time": "2023-04-09T22:53:37.241606Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_histogram_and_normal_dist(df, 'age', bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-09T22:53:37.130237Z",
     "end_time": "2023-04-09T22:53:37.422470Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_histogram_and_normal_dist(df, 'fare', bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsderstanding relationships between variables\n",
    "Measuting the relationship between two variables is important in order to understand the data. There are several ways to measure the relationship between two variables. The covariance and the correlation coefficient are two of the most common.\n",
    "\n",
    "#### Covariance\n",
    "\n",
    "The covariance is a measure of the joint variability of two random variables. It shows the degree to which two variables change together. i.e., if the two variables tend to increase together or decrease together and by how much.\n",
    "\n",
    "The covariance is calculated using the following formula:\n",
    "$$\\text{cov}(x,y) = \\frac{1}{n}\\sum_{i=1}^{n}(x_i - \\bar{x})(y_i - \\bar{y})$$\n",
    "where $x_i$ is the $i$-th value of the variable $x$, $\\bar{x}$ is the mean of the variable $x$, $y_i$ is the $i$-th value of the variable $y$, $\\bar{y}$ is the mean of the variable $y$, and $n$ is the number of values.\n",
    "\n",
    "The covariance varies between -$\\infty$ and $\\infty$. The covariance is positive if the two variables tend to increase together, and negative if one variable tends to increase as the other decreases. The covariance is zero if the two variables are independent.\n",
    "\n",
    "The problem with the covariance is that it is difficult to interpret and it is not normalized. The covariance of two variables is not comparable to the covariance of two other variables. For example, the covariance of the fare and the age of the passengers is 143.3, while the covariance of the fare and the sibps of the passengers is 8.64. The covariance of the age and the fare of the passengers is much higher than the covariance of the fare and the sibps of the passengers. However, the age and the fare of the passengers are not more related than the age and the pclass of the passengers as we can see next from the correlation matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-09T22:53:37.424022Z",
     "end_time": "2023-04-09T22:53:37.433399Z"
    }
   },
   "outputs": [],
   "source": [
    "df.cov()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Correlation matrix\n",
    "Correlation matrix allow to see the correlation between the numerical columns. The correlation coefficient ranges from -1 to 1. A value of 1 means that there is a perfect positive correlation between the two columns, a value of -1 means that there is a perfect negative correlation between the two columns, and a value of 0 means that there is no correlation between the two columns. The correlation matrix is a symmetric matrix, so we only need to plot the upper triangle of the matrix.\n",
    "\n",
    "The correlation between two variables is calculated using the following formula:\n",
    "$$\\text{corr}(x,y) = \\frac{\\text{cov}(x,y)}{\\sigma_x \\sigma_y}$$\n",
    "where $\\sigma_x$ is the standard deviation of the variable $x$ and $\\sigma_y$ is the standard deviation of the variable $y$. The correlation coefficient is normalized, so it is comparable between different variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-09T22:53:37.436061Z",
     "end_time": "2023-04-09T22:53:37.467451Z"
    }
   },
   "outputs": [],
   "source": [
    "df.drop('body',axis=1).corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ploting the correlation matrix allow to see the correlation between the numerical columns in a more visual way. The seaborn library provides a heatmap function that allows to plot the correlation matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-09T22:53:37.445831Z",
     "end_time": "2023-04-09T22:53:37.859654Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.heatmap(df.corr(), annot=True, cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " This can also be done using the style.background_gradient() method from Pandas.\n",
    "\n",
    "<span style=\"color:red\"> - what conclusion can you draw from the correlation matrix? E.g., was age vs survided expectable or...?</span>\n",
    "\n",
    "<span style=\"color:red\"> - Would you be expecting a \"high\" correlation between age and body?</span>\n",
    "\n",
    "<span style=\"color:red\"> -Why is correlation between survived and body `nan`?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-09T22:53:37.861234Z",
     "end_time": "2023-04-09T22:53:37.906130Z"
    }
   },
   "outputs": [],
   "source": [
    "numeric_attributes = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "df[numeric_attributes].corr().style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another to have a good idea of the correlation between the numerical columns is to make a scatter plot matrix. Although in the case, due to the discrete nature of the data, the scatter plot matrix is not very useful/easy to interpret. Further, the scatter plot does not show the density of the data (e.g., you can not conclude from the scatter plot that the majority of the passengers were in the 3rd class, although the histogram of the pclass column shows that this is the case).\n",
    "\n",
    "<span style=\"color:red\"> - can you discerne the \"higher\" correlations?   </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-09T22:53:38.081712Z",
     "end_time": "2023-04-09T22:53:40.936423Z"
    }
   },
   "outputs": [],
   "source": [
    "_ = pd.plotting.scatter_matrix(df, figsize=(15, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spearman's rank correlation\n",
    "\n",
    "The Spearman's rank correlation is a nonparametric measure of the monotonicity of the relationship between two variables.  The Spearman's rank correlation is calculated using the following formula:\n",
    "$$\\text{corr}(x,y) = \\frac{\\text{cov}(\\text{rank}(x),\\text{rank}(y))}{\\sigma_{\\text{rank}(x)} \\sigma_{\\text{rank}(y)}}$$\n",
    "where $\\text{rank}(x)$ is the rank of the variable $x$ and $\\sigma_{\\text{rank}(x)}$ is the standard deviation of the rank of the variable $x$.\n",
    "\n",
    "For the Spearman's rank correlation, the variables do not need to be normally distributed. The Spearman's rank correlation is a monotonic measure, so it is not affected by the outliers. The Spearman's rank correlation is also not affected by the monotonic transformation of the variables.\n",
    "\n",
    "For example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-09T22:53:40.934312Z",
     "end_time": "2023-04-09T22:53:40.952962Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/9j/nv8p1yk95y5df79ppmw307_h0000gn/T/ipykernel_90973/4229777871.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mdf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcorr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmethod\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'spearman'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstyle\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackground_gradient\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcmap\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'coolwarm'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.corr(method='spearman').style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exercises\n",
    "\n",
    "[05_exercise_adult_part_1.ipynb](05_exercise_adult_part_1.ipynb)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
