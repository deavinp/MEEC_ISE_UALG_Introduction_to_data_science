{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyMongo\n",
    "The first step when working with PyMongo is to create a MongoClient to the running mongod instance.\n",
    "\n",
    "Make sure you have a MongoDB instance running - see [https://www.mongodb.com/docs/manual/administration/install-community/](https://www.mongodb.com/docs/manual/administration/install-community/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-04T11:03:30.600346Z",
     "start_time": "2024-03-04T11:03:30.593783Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from pymongo import MongoClient\n",
    "except:\n",
    "    !pip install pymongo\n",
    "    from pymongo import MongoClient\n",
    "\n",
    "try:\n",
    "    import psutil\n",
    "except:\n",
    "    !pip install psutil\n",
    "    import psutil"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Being a local server, you can create a client in several ways."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient()\n",
    "# same as \n",
    "#  client = MongoClient('localhost', 27017)\n",
    "# or \n",
    "#  client = MongoClient('mongodb://localhost:27017/')\n",
    "\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Databases \n",
    "A single client instance of MongoDB can support multiple independent databases. When working with PyMongo you access databases using **attribute style access** on MongoClient instances.\n",
    "\n",
    "So, the next line will \"connect\" to (or create if it does not exist) `sensorsDB` database.\n",
    "\n",
    "This also means that you have to be very careful with the naming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = client.sensorsDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collections \n",
    "A collection is a group of documents stored in MongoDB, and can be thought of as roughly the equivalent of a table in a relational database. Getting a collection in PyMongo works the same as getting a database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors_location = db.sensors_locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important note about collections (and databases) in MongoDB is that they are created lazily - none of the above commands have actually performed any operations on the MongoDB server. Collections and databases are created when the first document is inserted into them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insert documents\n",
    "\n",
    "To **insert a document** into a collection we can use the `insert_one()` method.\n",
    "\n",
    "One way is to create a document and pass it to the insert_one() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "        'location_name': 'Prometheus Server', \n",
    "        'description' : 'Prometheus Server @ lab. 163 / ISE /UAlg',\n",
    "        'sensor': [ \n",
    "                    {\n",
    "                        'sensor_name' : 'cpu_sensor', \n",
    "                        'unit' : 'percent'\n",
    "                    },\n",
    "                    {\n",
    "                        'sensor_name' : 'mem_sensor', \n",
    "                        'unit' : 'percent'\n",
    "                    }\n",
    "             ]\n",
    "       }"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The `insert_one()` method takes a document as its argument and returns an instance of the inserted document."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sensors_location.insert_one(data)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Further, we can get the `_id` of the inserted document. This is relevant when we want to use it later to update or delete the document or to relate it to other documents.\n",
    "\n",
    "The `_id` is a unique identifier for the document and is generated by the MongoDB server. The value is a 12-byte `ObjectId` which is generated based on the following components:\n",
    "\n",
    "- Timestamp: The first 4 bytes are a timestamp, representing the ObjectId's creation, measured in seconds since the Unix epoch. This provides the `ObjectId` with a natural order by time of creation.\n",
    "\n",
    "- Machine Identifier: The next 3 bytes are a unique identifier for the machine or process that generated the `ObjectId`. In older versions of MongoDB, this was the machine's hostname; in newer versions, it's a random value generated once per process. This ensures that ObjectIds generated on different machines or processes are likely to be unique.\n",
    "\n",
    "- Process ID: The next 2 bytes are the process ID that generated the `ObjectId`. This further disambiguates ObjectIds created simultaneously on the same machine or by processes with the same machine identifier.\n",
    "\n",
    "- Counter: The last 3 bytes are a counter, starting with a random value. This counter increments with each new ObjectId generated. It helps ensure uniqueness for ObjectIds created in the same second, on the same machine, by the same process.\n",
    "\n",
    "The combination of these components ensures that each ObjectId is unique across different machines, processes, and moments in time. This system avoids the need for a more costly centralized ID generation scheme and makes it easy to generate IDs in a distributed environment, which is crucial for the scalability of MongoDB.\n",
    "\n",
    "The 12-byte ObjectId format is compact and efficient, both in terms of storage space and performance. It also provides some level of timestamp-based sorting, which can be useful in certain applications."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_id = x.inserted_id\n",
    "location_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see what is on the `sensors_location` collection. To list all documents in the collection we can use the `find()` method which returns a cursor that can be used to iterate over the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import *\n",
    "\n",
    "for doc in sensors_location.find():\n",
    "    pprint(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, on the `sensors_readings`collection, we can insert on document for each reading of the sensor.\n",
    "\n",
    "Note: we'll use the `datetime` module to generate the timestamp and the `psutil` module to generate the value. The latest, psutil, is a package that provides access to many different system utilities, e.g., CPU usage, memory usage, disk usage, network usage etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import psutil\n",
    "\n",
    "for _ in range(200):\n",
    "    # creat the document\n",
    "    data = {\n",
    "           'sensor' : {'location_id': location_id, \n",
    "                       'sensor_name' : 'cpu_sensor' \n",
    "                      },\n",
    "            'value' : psutil.cpu_percent(interval=0.1),\n",
    "            'units' : 'percent',\n",
    "            'timestamp' : datetime.datetime.utcnow()\n",
    "           }\n",
    "    # send the document to the database\n",
    "    res = db.sensors_readings.insert_one(data)\n",
    "    print('.', end='')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let us store the last `_id` for latter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_id = res.inserted_id\n",
    "_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To list all inserted readings, we can use again the `find()` method and force the cursor to return all documents by calling the `list()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list(db.sensors_readings.find())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also list the inserted readings, sorted by value and timestamp. The `sort()` method allows us to sort the results by one or more fields, in this case `value` and `timestamp`. It receives a list of tuples with the field name and the sort order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list(\n",
    "    db.sensors_readings.find().sort([\n",
    "        ('value',-1),\n",
    "        ('timestamp', -1)]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the `ObjectId` (we stored ir earlier), it is possible to get one specific document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(list(db.sensors_readings.find({'_id': _id})))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Or find all documents with a value greater than 50%"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "query = {'value': {'$gt': 50}}\n",
    "pprint(list(db.sensors_readings.find(query)))"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the last 5 minutes..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "query = {'timestamp': {'$gt': datetime.datetime.utcnow() - datetime.timedelta(minutes=5)}}\n",
    "\n",
    "pprint(list(db.sensors_readings.find(query)))"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embending of information I\n",
    "In this approach, a single document contains **multiple sensors with a single read**. Also, embedded location info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import psutil\n",
    "\n",
    "for _ in range(200):\n",
    "    data = {\n",
    "        'location_name': 'Prometheus Server', \n",
    "        'description' : 'Prometheus Server @ lab. 163 / ISE /UAlg',\n",
    "        'sensors' : [ \n",
    "               {\n",
    "                   'sensor_name' : 'mem_sensor', \n",
    "                   'value' : psutil.virtual_memory().percent,\n",
    "                   'units' : 'percent'\n",
    "               },\n",
    "               {\n",
    "                   'sensor_name' : 'cpu_sensor', \n",
    "                   'value' : psutil.cpu_percent(interval=0.1),\n",
    "                   'units' : 'percent'\n",
    "               }\n",
    "           ],\n",
    "        'timestamp' : datetime.datetime.utcnow()\n",
    "    }\n",
    "    db.sensors_readings.insert_one(data)\n",
    "    print('.', end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the last insert. In this case we use the `limit(1)` method to limit the number of documents returned. Since the list is sorted by timestamp, the first one will be the last inserted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(\n",
    "    list(\n",
    "        db.sensors_readings.find()\\\n",
    "            .sort([('timestamp', -1)])\\\n",
    "            .limit(1)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embending of information II\n",
    "A single document contains multiple sensors - and multiple reads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'location_name': 'Prometheus Server', \n",
    "    'description' : 'Prometheus Server @ lab. 163 / ISE /UAlg',\n",
    "    'sensors' : [ \n",
    "           {\n",
    "               'sensor_name' : 'mem_sensor', \n",
    "               'values' :[] ,\n",
    "               'units' : 'percent'\n",
    "           },\n",
    "           {\n",
    "               'sensor_name' : 'cpu_sensor', \n",
    "               'values' : [],\n",
    "               'units' : 'percent'\n",
    "           }\n",
    "       ],\n",
    "}\n",
    "\n",
    "# get the readingd id to latter add values to the readings\n",
    "readings_id = db.sensors_readings.insert_one(data).inserted_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, in this implementation the **full document is upload each time a new read is made**. Which means that we need to update the document in the database each time a new read is made. To do this, we use the `update_one()` method which takes 2 arguments: the query and the update. A third argument are options which you can find in the documentation ([https://www.mongodb.com/docs/manual/reference/method/db.collection.update/](https://www.mongodb.com/docs/manual/reference/method/db.collection.update/))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(100):\n",
    "    mem = psutil.virtual_memory().percent\n",
    "    cpu = psutil.cpu_percent(interval=0.01)\n",
    "\n",
    "    # update the data\n",
    "    data['sensors'][0]['values'].append({'value': mem, 'timestamp' : datetime.datetime.utcnow()})\n",
    "    data['sensors'][1]['values'].append({'value': cpu, 'timestamp' : datetime.datetime.utcnow()})\n",
    "    # update the database, sending the full document again!!\n",
    "    db.sensors_readings.update_one(\n",
    "        {'_id': readings_id}, \n",
    "        {'$set': data}\n",
    "    )\n",
    "    \n",
    "    print('.', end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last reading is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = list(\n",
    "    db.sensors_readings.find() \\\n",
    "        .sort([('_id', -1)]) \\\n",
    "        .limit(1)\n",
    ")\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to get a value from it we can \"navigate\" the array/dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0]['sensors'][0]['values'][0]['value']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embending of information III\n",
    "As previously, a single document contains multiple sensors - and multiple reads. But now, only the fields we need are updated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import psutil\n",
    "\n",
    "data = {\n",
    "    'location_name': 'Prometheus Server', \n",
    "    'description' : 'Prometheus Server @ lab. 163 / ISE /UAlg', \n",
    "    'sensors' : [ \n",
    "           {\n",
    "               'sensor_name' : 'mem_sensor', \n",
    "               'values' : [],\n",
    "               'units' : 'percent'\n",
    "           },\n",
    "           {\n",
    "               'sensor_name' : 'cpu_sensor', \n",
    "               'values' : [],\n",
    "               'units' : 'percent'\n",
    "           }\n",
    "       ]\n",
    "}\n",
    "\n",
    "readings_id = db.sensors_readings.insert_one(data).inserted_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, a first document was inserted with no sensors values. The document `_id` was stored and in the following data will be appended/pushed to the corresponding document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(200):\n",
    "    mem = psutil.virtual_memory().percent\n",
    "    cpu = psutil.cpu_percent(interval=0.1)\n",
    "    \n",
    "    # update the database, sending only the update\n",
    "    db.sensors_readings.update_one(\n",
    "        {'_id': readings_id}, \n",
    "        {\n",
    "            '$push': {\n",
    "                'sensors.0.values': {'value': mem, 'timestamp' : datetime.datetime.utcnow()},\n",
    "                'sensors.1.values': {'value': cpu, 'timestamp' : datetime.datetime.utcnow()}        \n",
    "            }\n",
    "        }\n",
    "    )    \n",
    "    \n",
    "    print('.', end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last reading is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pprint(\n",
    "    list(\n",
    "        db.sensors_readings\\\n",
    "            .find()\\\n",
    "            .sort([('_id', -1)])\\\n",
    "            .limit(1)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Documents\n",
    "Getting a single document with find_one() can be done using the `find_one()` method which returns the first document in the collection which matches the query. The syntax is the same as the `find()` method, i.e., `find_one({query}, {projection})` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.sensors_readings.find_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find one reading from \"Prometheus Server\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.sensors_readings.find_one({'location_name':'Prometheus Server'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the Object id for one reading on the sensor's reading collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_id = db.sensors_readings.find_one({'location_name':'Prometheus Server'})[\"_id\"]\n",
    "obj_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Querying By ObjectId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bson.objectid import ObjectId\n",
    "\n",
    "db.sensors_readings.find_one({'_id': obj_id})  # update the _id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do projections, i.e., select which fields to present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "db.sensors_readings.find_one(\n",
    "    {'_id': obj_id},\n",
    "    {'sensors':1}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bulk Insert\n",
    "In addition to inserting a single document, we can also perform bulk insert operations, by passing a list as the first argument to insert_many(). This will insert each document in the list, sending only a single command to the server.\n",
    "\n",
    "The result from insert_many() now returns multiple ObjectId instances, one for each inserted document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_posts = [{\n",
    "                'sensor': {'location_id': ObjectId('5a95821bdc936e0cfc7c7d96'),\n",
    "                'sensor_name': 'cpu_sensor'},\n",
    "                'timestamp': datetime.datetime.utcnow(),\n",
    "                'units': 'percent',\n",
    "                'value': 4.5\n",
    "            },\n",
    "             {\n",
    "                'sensor': {'location_id': ObjectId('5a95821bdc936e0cfc7c7d96'),\n",
    "                'sensor_name': 'cpu_sensor'},\n",
    "                'timestamp': datetime.datetime.utcnow(),\n",
    "                'units': 'percent',\n",
    "                'value': 4.5\n",
    "             }\n",
    "            ]\n",
    "result = db.sensors_readings.insert_many(new_posts)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and get the id's of the inserted objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.inserted_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Querying for More Than One Document\n",
    "\n",
    "To get more than a single document as the result of a query we use the find() method. find() returns a Cursor instance, which allows us to iterate over all matching documents. \n",
    "\n",
    "Note that do to our experiments, the documents no not follow any type of schema. This is not recommended but is possible. So, fields like timestamp are found in every document, but in different \"positions\" in the document. \n",
    "\n",
    "For example, we can iterate over every document in the posts collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for doc in db.sensors_readings.find():\n",
    "    pprint(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can also limit the output and order it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in db.sensors_readings.find().sort([('_id',1)]).limit(2):\n",
    "    pprint(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting\n",
    "If we just want to know how many documents match a query we can perform a count_documents() operation instead of a full query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.sensors_readings.count_documents({})"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "It is also possible to count the number of documents in a collection satisfying a query"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {'location_name':'Prometheus Server'}\n",
    "db.sensors_readings.count_documents(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Range Queries\n",
    "MongoDB supports many different types of advanced queries.\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "last_inserted_doc_timestamp = db.sensors_readings.find().sort([('_id',-1)]).limit(1)[0]['timestamp']\n",
    "last_inserted_doc_timestamp"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in db.sensors_readings.find({'timestamp': last_inserted_doc_timestamp}):\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "As an example, lets perform a query where we limit results to readings insertd in the last 5 minutes:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "date = datetime.datetime.utcnow() - datetime.timedelta(minutes=5)\n",
    "query = {'timestamp': {'$gt': date}}\n",
    "for doc in db.sensors_readings.find(query):\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "All readings witha `value` lower than 10"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in db.sensors_readings.find({'value': {'$lt': 10}}):\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "All CPU readings with `value` lower than 10 in the next type of documents\n",
    "\n",
    "![./images/doc_example.png](./images/doc_example.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in db.sensors_readings.find({'sensors.1.values.value': {'$gt': 10}}):\n",
    "    print(doc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
